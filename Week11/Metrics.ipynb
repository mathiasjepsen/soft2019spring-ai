{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Metrics\n",
    "\n",
    "* Categorical metrics \n",
    "  * F1\n",
    "* Regression metrics\n",
    "    * Mean absolute error\n",
    "    * Root mean squared error\n",
    "    * Pearson's R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Classification\n",
    "\n",
    "* Precision\n",
    "\n",
    "$$ \\text{precision}=\\frac{|\\{\\text{relevant documents}\\}\\cap\\{\\text{retrieved documents}\\}|}{|\\{\\text{retrieved documents}\\}|} $$\n",
    "* Recall\n",
    "$$\\text{recall}=\\frac{|\\{\\text{relevant documents}\\}\\cap\\{\\text{retrieved documents}\\}|}{|\\{\\text{relevant documents}\\}|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Accuracy\n",
    "  * Fraction of correct predictions\n",
    "  $$ {\\text{Correct predictions} \\over \\text{All predictions}} $$\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](images/accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This shows all the data that we have seen. What about the data we *haven't* seen?\n",
    "\n",
    "How can we explain the fact that a test might not have perfect recall?\n",
    "\n",
    "* Jacob's airplane example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## F1 score\n",
    "\n",
    "$$F_1 = \\left(\\frac{\\mathrm{recall}^{-1} + \\mathrm{precision}^{-1}}{2}\\right)^{-1} = 2 \\cdot \\frac{\\mathrm{precision} \\cdot \\mathrm{recall}}{\\mathrm{precision} + \\mathrm{recall}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "target = [1]\n",
    "predicted = [1]\n",
    "f1_score(target, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f1_score([1], [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f1_score([[1], [0]], [[1], [1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Model fitness for linear models\n",
    "\n",
    "**Actual** observed target: $y$\n",
    "\n",
    "**Predicted** value from the model: $\\hat{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mean absolute error\n",
    "\n",
    "$$\\mathrm{MAE} = \\frac{\\sum_{i=1}^n\\left| y_i-\\hat{y}_i\\right|}{n} =\\frac{\\sum_{i=1}^n\\left| e_i \\right|}{n}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Controls for sample size\n",
    "  * \"Controls\" means \"takes into account\"\n",
    "* Not sensitive to outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mean squared error\n",
    "\n",
    "$$\\mathrm{MSE} = \\frac{\\sum_{i=1}^n\\left| y_i-\\hat{y}_i\\right|^2}{n} =\\frac{\\sum_{i=1}^n\\left| e_i \\right|^2}{n}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Controls for sample size\n",
    "* Not sensitive to outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Root mean squared error\n",
    "\n",
    "$$\\mathrm{RMSE} = \\sqrt{\\frac{\\sum_{i=1}^n\\left| y_i-\\hat{y}_i\\right|^2}{n}} = \\sqrt{\\frac{\\sum_{i=1}^n\\left| e_i \\right|^2}{n}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Controls for sample size\n",
    "* Sensitive to outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pearson's R\n",
    "\n",
    "Describes the portion of variance (change) in the data that the model can predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Imagine a model without any $x$ values.\n",
    "\n",
    "$$\\bar{y}=\\frac{1}{n}\\sum_{i=1}^n y_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then we could get the total change in the data as the sum of squares (SS):\n",
    "\n",
    "$$SS_\\text{tot}=\\sum_i (y_i-\\bar{y})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And if we compare that to the *actual* error:\n",
    "$$ SS_\\text{res}=\\sum_i (y_i - f_i)^2=\\sum_i e_i^2\\$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can know how much the model is able to predict, compared to the baseline data variance:\n",
    "\n",
    "$$R^2 \\equiv 1 - {SS_{\\rm res}\\over SS_{\\rm tot}}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Coefficient_of_Determination.svg/800px-Coefficient_of_Determination.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So, for each point, how much error do we add to the explanation of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score([1], [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "r2_score([1, 2], [1, 1.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Run the $R^2$ score on the following data and explain the *meaning* of that value:\n",
    "\n",
    "| Target | Predicted | \n",
    "| --- | --- |\n",
    "| `[2]` | `[2]` |\n",
    "| `[1, 2]` | `[1, 1.999999]` |\n",
    "| `[1, 5, 3]` | `[1, 5, 2]` |\n",
    "| `[2, 7]` | `[1.8, 7.2]` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Recap \n",
    "\n",
    "* F1 score for classification tasks\n",
    "* $R^2$ score for regression tasks"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
